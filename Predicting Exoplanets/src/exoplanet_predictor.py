# -*- coding: utf-8 -*-
"""
Created on Fri Apr  2 15:45:10 2021

@author: David
"""
# %% Imports
# Import libraries
from datetime import datetime

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import pandas as pd
from pandas.plotting import scatter_matrix
from pandas_profiling import ProfileReport
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split, \
                                    cross_val_score, \
                                    cross_val_predict
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

# %% read dataset
# Read the Kepler Objects of Interest (KOI) dataset and look at one observation
df_koi = pd.read_csv('../DSC680/Predicting Exoplanets/data/cumulative_2021.03.16_17.10.21.csv')
print(df_koi.shape)
print(df_koi[1:2].T)

# %% clean data
# Remove variables with no data
df_koi_cleaned = df_koi.dropna(axis=1, how='all')

# Remove columns containing only zero
df_koi_cleaned = df_koi_cleaned.loc[:, (df_koi_cleaned != 0).any(axis=0)]

# Remove the err columns
df_koi_cleaned = df_koi_cleaned[df_koi_cleaned.columns.drop(
    list(df_koi_cleaned.filter(regex='_err')))]

# %% remove 0.0 columns
# Still some variables that are all 0.0; will just drop them manually...
cols = ['koi_eccen','koi_ldm_coeff4','koi_ldm_coeff3']
df_koi_cleaned = df_koi_cleaned.drop(cols,axis=1)
df_koi_cleaned.shape

# %% describe
df_describe = pd.DataFrame(df_koi_cleaned.describe())
print(df_describe)

# %% create subsets
transit_columns = ['koi_period', 'koi_time0bk', 'koi_time0', 'koi_impact', 
                   'koi_duration', 'koi_depth', 'koi_ror', 'koi_srho', 'koi_fittype', 
                   'koi_prad', 'koi_sma', 'koi_incl', 'koi_teq', 'koi_insol', 'koi_dor', 
                   'koi_limbdark_mod', 'koi_ldm_coeff2', 'koi_ldm_coeff1', 'koi_parm_prov']
tce_columns = ['koi_max_sngle_ev', 'koi_max_mult_ev', 'koi_model_snr', 'koi_count', 
               'koi_num_transits', 'koi_tce_plnt_num', 'koi_tce_delivname', 'koi_quarters', 
               'koi_trans_mod', 'koi_datalink_dvr', 'koi_datalink_dvs']
stellar_columns = ['koi_steff', 'koi_slogg', 'koi_smet', 'koi_srad', 'koi_smass', 'koi_sparprov']
kic_columns = ['ra', 'dec', 'koi_kepmag', 'koi_gmag', 'koi_rmag', 'koi_imag', 'koi_zmag', 
               'koi_jmag', 'koi_hmag', 'koi_kmag']
pixel_columns = ['koi_fwm_sra', 'koi_fwm_sdec', 'koi_fwm_srao', 'koi_fwm_sdeco', 'koi_fwm_prao', 
                 'koi_fwm_pdeco', 'koi_fwm_stat_sig', 'koi_dicco_mra', 'koi_dicco_mdec', 
                 'koi_dicco_msky', 'koi_dikco_mra', 'koi_dikco_mdec', 'koi_dikco_msky']


df_transit = df_koi_cleaned[transit_columns]
df_tce = df_koi_cleaned[tce_columns]
df_stellar = df_koi_cleaned[stellar_columns]
df_kic = df_koi_cleaned[kic_columns]
df_pixel = df_koi_cleaned[pixel_columns]

# %% pandas profiling
# Suppress SettingWithCopyWarning message generated by he pandas-profiling package
import warnings
warnings.simplefilter(action='ignore')

profile = ProfileReport(df_transit, title="Pandas Profiling Report")
# profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True)
pfile = "profile_report_{}.html".format(datetime.now().strftime('%m%d%y%H%M'))
profile.to_file(pfile)

# %% transit variables
"""
The 3 categorical variables did not display much variation. In fact, koi_limbdark_mod 
was a constant value while koi_fittype and koi_parm_prov had a constant value in 
roughly 80% of the observations.
"""
cat_cols = ['koi_limbdark_mod', 'koi_fittype', 'koi_parm_prov']
df_transit = df_transit.drop(cat_cols, axis=1)

# Replace missing numerical values with the median
imputer = SimpleImputer(strategy="median")
imputer.fit(df_transit)
X = imputer.transform(df_transit)
df_transit_final = pd.DataFrame(X, columns=df_transit.columns, index=df_transit.index)

# %% PCA function
def pca(df):
    
    # standardize the features matrix
    features = StandardScaler().fit_transform(df)
    
    # Create a PCA that retains 99% of the variance
    pca = PCA(n_components = 0.95)
    features_pca = pca.fit_transform(features)
    
    return features, features_pca

# %% Dimensionality Reduction
features, features_pca = pca(df_transit_final)
print('Original number of features: {}'.format(features.shape[1]))
print('Reduced number of features: {}'.format(features_pca.shape[1]))

# %% train and test sets
labels = np.array(df_koi_cleaned['koi_disposition'])

train_features, test_features, train_labels, test_labels = train_test_split(
    features_pca, labels, test_size = 0.25, random_state = 42)

print('Training Features Shape:', train_features.shape)
print('Training Labels Shape:', train_labels.shape)
print('Testing Features Shape:', test_features.shape)
print('Testing Labels Shape:', test_labels.shape)
# %% train model
# Instantiate model with 1000 decision trees
rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)
rf.fit(train_features, train_labels)
print(train_features, train_labels)

predictions = rf.predict(test_features)
print(accuracy_score(test_labels, predictions))
print(recall_score(test_labels, predictions, average=None))

# %% performance
print(cross_val_score(rf, train_features, train_labels, cv=3, scoring='accuracy'))

# %% confusion matrix
train_pred = cross_val_predict(rf, train_features,train_labels, cv=3)
conf_matrix_rf = confusion_matrix(train_labels, train_pred)

# %% Torrey
fig, ax = plt.subplots(figsize = (10,8))

sns.heatmap(conf_matrix_rf/np.sum(conf_matrix_rf), annot=True, 
            fmt='.2%', cmap='Blues', annot_kws={'size':15})

ax.set_title('Random Forest Confusion Matrix', fontsize = 18, loc='left')

ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12)
ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 12)

plt.show()

# %%

