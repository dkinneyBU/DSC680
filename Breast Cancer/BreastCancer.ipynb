{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Prediction and Detection\n",
    "### via Machine Learning and Deep Learning  \n",
    "\n",
    "### David Kinney - DSC680 - Spring 2021 - Professor Catherine Williams\n",
    "**********************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Prediction - Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Breast Cancer Wisconsin (Diagnostic) dataset\n",
    "df = pd.read_csv('./data/data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 32'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************************************\n",
    "### Machine Learning Model Selection, Training and Tuning  \n",
    "\n",
    "#### Initialize PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf1 = setup(df, target = 'diagnosis', \n",
    "             session_id=8784, \n",
    "             log_experiment=True, \n",
    "             experiment_name='BCpred')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create best model from baseline results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model('xgboost', gpu_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tune hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = tune_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, plot = 'boundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, plot = 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, plot = 'pr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, plot = 'class_report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_model(model, plot = 'correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_holdouts = predict_model(model)\n",
    "pred_holdouts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************\n",
    "## Breast Cancer Detection via Deep Learning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from fastai import *\n",
    "# from fastai.data.transforms import get_files, Path\n",
    "# from fastai.metrics import error_rate\n",
    "from fastai.vision.transform import get_transforms\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fast.utils.mem import GPUMemTrace"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def getFiles(inputElement, extensions = \"[png]\", recursive = False):\n",
    "    \"\"\" Get the list of files with certain extensions contained in the folder (and possible\n",
    "    subfolders) given by inputElement. If inputElement is directly a file it\n",
    "    returns a list with only one element, the given file \"\"\"\n",
    "    # If extensions is not a list but a string we converted to a list\n",
    "    if type(extensions) == str:\n",
    "        extensions = [extensions,]\n",
    "    # If input element is file, return it\n",
    "    if(os.path.isfile(inputElement)):\n",
    "        fname,fext = os.path.splitext(inputElement)\n",
    "        return [inputElement] if fext.lower() in extensions else []\n",
    "    # Else, use recursive globbing\n",
    "    files = []\n",
    "    globpath = os.path.join(inputElement,'**') if recursive else inputElement\n",
    "    for ext in extensions:\n",
    "        files.extend(glob2.glob(os.path.join(globpath,'*.' + ext)))\n",
    "        files.extend(glob2.glob(os.path.join(globpath,'*.' + ext.upper())))\n",
    "    return list(set(files)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Our image dataset is stored as .jpg files in 2 different folders, with each \n",
    "folder bearing the name of model of the images contained in the folder. \"\"\"\n",
    "\n",
    "x  = \"./data/images\"\n",
    "path = Path(x)\n",
    "pattern= r'([^/_]+).png$'\n",
    "fnames=get_files(path, recurse=True)\n",
    "tfms=get_transforms(flip_vert=True, max_warp=0., max_zoom=0., max_rotate=0.)\n",
    "# path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(61)\n",
    "data = ImageDataBunch.from_name_re(path, fnames, pattern, ds_tfms=tfms, size=50, bs=64,num_workers=4\n",
    "                                  ).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 0 = benign, class 1 = malignant\n",
    "data.show_batch(rows=3, figsize=(7,6),recompute_scale_factor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = listdir(x)\n",
    "class_0_total = 0\n",
    "class_1_total = 0\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    class_0_files = listdir(train + patient_id + '/0')\n",
    "    class_1_files = listdir(train + patient_id + '/1')\n",
    "    class_0_total += len(class_0_files)\n",
    "    class_1_total += len(class_1_files) \n",
    "\n",
    "total_images = class_0_total + class_1_total\n",
    "    \n",
    "print(f'Number of patches in Class 0: {class_0_total}')\n",
    "print(f'Number of patches in Class 1: {class_1_total}')\n",
    "print(f'Total number of patches: {total_images}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context='notebook', style='darkgrid', palette='colorblind', font='sans-serif', font_scale=1, rc=None)\n",
    "matplotlib.rcParams['figure.figsize'] =[8,8]\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_perc = data.groupby(\"patient_id\").target.value_counts()/ data.groupby(\"patient_id\").target.size()\n",
    "cancer_perc = cancer_perc.unstack()\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(25,5))\n",
    "\n",
    "# Plotting Frequency of Patches per Patient\n",
    "sns.distplot(data.groupby(\"patient_id\").size(), ax=ax[0], color=\"green\", kde=False, bins=20)\n",
    "ax[0].set_xlabel(\"Number of patches\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].set_title(\"How many patches do we have per patient?\")\n",
    "\n",
    "# Plotting Percentage of an image that is covered by Invasive Ductile Carcinoma\n",
    "sns.distplot(cancer_perc.loc[:, 1]*100, ax=ax[1], color=\"red\", kde=False, bins=20)\n",
    "ax[1].set_title(\"How much percentage of an image is covered by IDC?\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    "ax[1].set_xlabel(\"% of patches with IDC\")\n",
    "\n",
    "# Plotting number of patches that show IDC\n",
    "sns.countplot(data.target, palette='pastel', ax=ax[2]);\n",
    "ax[2].set_ylabel(\"Count\")\n",
    "ax[2].set_xlabel(\"no(0) versus yes(1)\")\n",
    "ax[2].set_title(\"How many patches show IDC?\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model\n",
    "\n",
    "We now use a pre-trained `ResNet18 Convolutional Neural Net` model, and use *transfer learning* to learn weights of only the last layer of the network.   \n",
    "Why Transfer learning? Because with transfer learning, you begin with an existing (trained) neural network used for image recognition — and then tweak it a bit (or more) here and there to train a model for your particular use case. And why do we do that? Training a reasonable neural network would mean needing approximately 300,000 image samples, and to achieve really good performance, we’re going to need at least a million images.  \n",
    "In our case, we have approximately 4000+ images in our training set — you have one guess to decide if that would have been enough if were to train a neural net from scratch.  \n",
    "We use the create_cnn() function for loading a pre-trained ResNet18 network, that was trained on around a million images from the ImageNet database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data, models.resnet18, \n",
    "                    metrics=[accuracy], \n",
    "                    model_dir = Path('./data/working'),\n",
    "                    path = Path(\".\"))\n",
    "learn.model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot the learning rate\n",
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and tune a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = 1e-3\n",
    "lr2 = 1e-1\n",
    "with GPUMemTrace:\n",
    "    learn.fit_one_cycle(1,slice(lr1,lr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr1 = 1e-3\n",
    "lr = 1e-1\n",
    "with GPUMemTrace:\n",
    "    learn.fit_one_cycle(1,slice(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypermaramter tuning\n",
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.recorder.plot()\n",
    "with GPUMemTrace:\n",
    "    learn.fit_one_cycle(1,slice(1e-4,1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "\n",
    "import fnmatch\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePatches = glob('./data/images/**/*.png', recursive=True)\n",
    "len(imagePatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patternZero = '*class0.png'\n",
    "patternOne = '*class1.png'\n",
    "classZero = fnmatch.filter(imagePatches, patternZero)\n",
    "classOne = fnmatch.filter(imagePatches, patternOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "555048/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for img in imagePatches:\n",
    "    if img in classZero:\n",
    "        y.append(0)\n",
    "    elif img in classOne:\n",
    "        y.append(1)\n",
    "        \n",
    "images_df = pd.DataFrame()\n",
    "images_df[\"images\"] = imagePatches\n",
    "images_df[\"labels\"] = y\n",
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df.groupby(\"labels\")[\"labels\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and val\n",
    "train, val = train_test_split(images_df, stratify=images_df.labels, test_size=0.2)\n",
    "len(train), len(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df_data,transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df_data.values\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path,label = self.df[index]\n",
    "        \n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (50,50))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters for model\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 2\n",
    "batch_size = 128\n",
    "learning_rate = 0.002\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                  transforms.Pad(64, padding_mode='reflect'),\n",
    "                                  transforms.RandomHorizontalFlip(), \n",
    "                                  transforms.RandomVerticalFlip(),\n",
    "                                  transforms.RandomRotation(20), \n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "trans_valid = transforms.Compose([transforms.ToPILImage(),\n",
    "                                  transforms.Pad(64, padding_mode='reflect'),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset_train = MyDataset(df_data=train, transform=trans_train)\n",
    "dataset_valid = MyDataset(df_data=val,transform=trans_valid)\n",
    "\n",
    "loader_train = DataLoader(dataset = dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "loader_valid = DataLoader(dataset = dataset_valid, batch_size=batch_size//2, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # ancestor constructor call\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.avg = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(512 * 1 * 1, 2) # !!!\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x)))) # first convolutional layer then batchnorm, then activation then pooling layer.\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn5(self.conv5(x))))\n",
    "        x = self.avg(x)\n",
    "        #print(x.shape) # lifehack to find out the correct dimension for the Linear Layer\n",
    "        x = x.view(-1, 512 * 1 * 1) # !!!\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "total_step = len(loader_train)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(loader_train):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "confusion_matrix = torch.zeros(2, 2)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader_valid:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        for t, p in zip(labels.view(-1), predicted.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "                 \n",
    "    print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
